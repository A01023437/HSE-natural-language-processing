{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.9"
    },
    "colab": {
      "name": "Copy of Honor_chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAVW-MVm9qf3",
        "colab_type": "text"
      },
      "source": [
        "## Project\n",
        "#### Description:\n",
        "\n",
        "* In this project, text generation is implemented with an RNN with GRU, based\n",
        "on the text by Isaac Asimov, The Foundation.\n",
        "*   Based on the implementation: https://www.tensorflow.org/tutorials/text/text_generation#generate_text\n",
        "*   This uses the dataset from The Foundation by Isaac Asimov.\n",
        "* Details: see each comment and block with explanations.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### 1. Download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWNvCHoa9qf6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "2ee5c0a2-e7b6-49ed-c838-2492fbe194ae"
      },
      "source": [
        "!wget https://ia800708.us.archive.org/35/items/Foundation_201811/3%20Foundation_djvu.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-14 19:46:44--  https://ia800708.us.archive.org/35/items/Foundation_201811/3%20Foundation_djvu.txt\n",
            "Resolving ia800708.us.archive.org (ia800708.us.archive.org)... 207.241.230.78\n",
            "Connecting to ia800708.us.archive.org (ia800708.us.archive.org)|207.241.230.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 423786 (414K) [text/plain]\n",
            "Saving to: ‘3 Foundation_djvu.txt.2’\n",
            "\n",
            "3 Foundation_djvu.t 100%[===================>] 413.85K   735KB/s    in 0.6s    \n",
            "\n",
            "2020-08-14 19:46:45 (735 KB/s) - ‘3 Foundation_djvu.txt.2’ saved [423786/423786]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjPLzvM59qgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkV4Q3PZHB2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "d0e9d30f-6e01-46b9-de2c-23910ae0bc97"
      },
      "source": [
        "tf.test.is_gpu_available()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7xSNDN_9qgg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "734e628f-8c47-41bf-c686-02d4ab85dadd"
      },
      "source": [
        "# Read, then decode.\n",
        "text = open('3 Foundation_djvu.txt', 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))\n",
        "\n",
        "print(text[:500])\n",
        "text.find('THE STORY')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 411158 characters\n",
            "ASI MOV \n",
            "\n",
            "\n",
            "THE FOUNDATION NOVELS \n",
            "\n",
            "\n",
            "\n",
            "FOUNDATION \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "FOUNDATION \n",
            "\n",
            "\n",
            "ISAAC ASIMOV \n",
            "\n",
            "Copyright © 1951 \n",
            "\n",
            "\n",
            "To the memory of my mother (1895 — 1973) \n",
            "\n",
            "\n",
            "Contents \n",
            "\n",
            "\n",
            "THE STORY BEHIND THE “FOUNDATION” \n",
            "\n",
            "PART I - THE PSYCHOHISTORIANS \n",
            "\n",
            "PART II - THE ENCYCLOPEDISTS \n",
            "\n",
            "PART III - THE MAYORS \n",
            "\n",
            "PART IV - THE TRADERS \n",
            "\n",
            "PART V - THE MERCHANT PRINCES \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "THE STORY BEHIND THE \"FOUNDATION” \n",
            "\n",
            "\n",
            "By ISAAC ASIMOV \n",
            "\n",
            "\n",
            "The date was August 1, 1941. World War II had been raging for two years. \n",
            "France had fal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQUNWc0J9qgv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8d8eeb4-01e2-4976-86ae-c66bfd3e97a6"
      },
      "source": [
        "# find where text starts.\n",
        "text.find('By ISAAC ASIMOV')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "393"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SplBZOvZ9qg4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "043721a3-5d78-431b-af2e-b470da7154d0"
      },
      "source": [
        "# crop\n",
        "text = text[393:]\n",
        "text[:500]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'By ISAAC ASIMOV \\n\\n\\nThe date was August 1, 1941. World War II had been raging for two years. \\nFrance had fallen, the Battle of Britain had been fought, and the Soviet Union \\nhad just been invaded by Nazi Germany. The bombing of Pearl Harbor was four \\nmonths in the future. \\n\\nBut on that day, with Europe in flames, and the evil shadow of Adolf \\nHitler apparently falling over all the world, what was chiefly on my mind was a \\nmeeting toward which I was hastening. \\n\\nI was 21 years old, a graduate stud'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW4yX-on9qhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "a50e7575-51b0-474f-f790-3a3bd88a07d4"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print ('{} unique characters'.format(len(vocab)))\n",
        "\n",
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "\n",
        "\n",
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87 unique characters\n",
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '\"' :   3,\n",
            "  '$' :   4,\n",
            "  '%' :   5,\n",
            "  \"'\" :   6,\n",
            "  '(' :   7,\n",
            "  ')' :   8,\n",
            "  '*' :   9,\n",
            "  ',' :  10,\n",
            "  '-' :  11,\n",
            "  '.' :  12,\n",
            "  '/' :  13,\n",
            "  '0' :  14,\n",
            "  '1' :  15,\n",
            "  '2' :  16,\n",
            "  '3' :  17,\n",
            "  '4' :  18,\n",
            "  '5' :  19,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i28Xn6wmdTZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7c426d6-c8ca-4656-d2c5-73f7f92f939a"
      },
      "source": [
        "\n",
        "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'By ISAAC ASIM' ---- characters mapped to int ---- > [28 78  1 35 45 27 27 29  1 27 45 35 39]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2Guc4WZdZZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ced4b82f-2a8c-4cb6-de01-5a1942e1d948"
      },
      "source": [
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B\n",
            "y\n",
            " \n",
            "I\n",
            "S\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZo7LwVieCn2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "7b1c4b17-6ede-4208-d857-6aef600d8d9d"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'By ISAAC ASIMOV \\n\\n\\nThe date was August 1, 1941. World War II had been raging for two years. \\nFrance h'\n",
            "'ad fallen, the Battle of Britain had been fought, and the Soviet Union \\nhad just been invaded by Nazi'\n",
            "' Germany. The bombing of Pearl Harbor was four \\nmonths in the future. \\n\\nBut on that day, with Europe '\n",
            "'in flames, and the evil shadow of Adolf \\nHitler apparently falling over all the world, what was chief'\n",
            "'ly on my mind was a \\nmeeting toward which I was hastening. \\n\\nI was 21 years old, a graduate student i'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwxecXAieE0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDvCGkF4eH2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b2038d94-c068-45f1-d007-f48ec9bd1c84"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'By ISAAC ASIMOV \\n\\n\\nThe date was August 1, 1941. World War II had been raging for two years. \\nFrance '\n",
            "Target data: 'y ISAAC ASIMOV \\n\\n\\nThe date was August 1, 1941. World War II had been raging for two years. \\nFrance h'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1rA7bJCeI-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "ddb8030a-3552-4462-8e6a-1543e13d15fe"
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "  print(\"Step {:4d}\".format(i))\n",
        "  print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "  print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 28 ('B')\n",
            "  expected output: 78 ('y')\n",
            "Step    1\n",
            "  input: 78 ('y')\n",
            "  expected output: 1 (' ')\n",
            "Step    2\n",
            "  input: 1 (' ')\n",
            "  expected output: 35 ('I')\n",
            "Step    3\n",
            "  input: 35 ('I')\n",
            "  expected output: 45 ('S')\n",
            "Step    4\n",
            "  input: 45 ('S')\n",
            "  expected output: 27 ('A')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR9WYQmZeL4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eaff49cd-1a62-471c-bf12-980bc8836404"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrhDcsBAdyCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuXZq37leQ5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIb_YxLEdzJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "    vocab_size = len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s_YWAW0eUOX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fa1be56-3fb0-4751-eb3e-6183a1b7a53c"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 87) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtaWLYxUeUUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "d5fbb086-68a7-4bda-bb6e-d26a95c24aa6"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           22272     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 87)            89175     \n",
            "=================================================================\n",
            "Total params: 4,049,751\n",
            "Trainable params: 4,049,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpXna3QxeUds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "eed0afc2-7582-4631-d60b-12e3ab7970cb"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13,  4, 32,  2, 56, 61,  8, 35, 70, 37, 75, 22, 70, 26, 18, 65, 65,\n",
              "       36, 21, 31, 66, 60, 51, 84, 18, 40, 61, 48, 86,  7, 63,  6, 72, 57,\n",
              "        0, 43, 39,  5,  5, 16, 47, 60,  6, 10, 49, 35, 73, 57, 78, 72, 53,\n",
              "       22, 24, 80, 75, 41, 66, 50, 10, 80, 21, 56, 52, 53, 79,  2, 53, 68,\n",
              "       27, 86, 59, 65, 25,  5, 17, 48,  1, 78, 23, 63, 42, 75, 62, 73, 33,\n",
              "       58, 71, 48, 11, 61,  1, 14, 28, 22, 33,  5, 72, 56, 79,  9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfDJa5LliRbD",
        "colab_type": "text"
      },
      "source": [
        "## Experiment.\n",
        "To check how it works (a bunch of mumbo-jumbo is expected as model is NOT trained yet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv2z2A7zecFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "bad0fd11-75a2-4358-cf52-da79855a0f61"
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " '. That was for the inhabitants of Terminus itself. The men of the Outer \\nPlanets could hear only cen'\n",
            "\n",
            "Next Char Predictions: \n",
            " \"/$F!ch)IqKv8q?4llJ7EmgY’4NhV”(j'sd\\nQM%%2Ug',WItdys^8:~vOmX,~7cZ^z!^oA”fl;%3V y9jPvitGerV-h 0B8G%scz*\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVcjeyIVegEJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "142f1130-59e7-4094-8cbc-30dcb87aa2a0"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 87)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.464743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p-Vpv-6ejQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdqDxtQ1ek9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S01Lu35Zi4dn",
        "colab_type": "text"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1KWDYeLenCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRM2t3JEe1uY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3051cfe-f589-4793-becf-6bab2673fa2c"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoints/ckpt_100'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2qBdtShe4ic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "8db91671-d7d0-4a87-b6a7-4776653f77c4"
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            22272     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 87)             89175     \n",
            "=================================================================\n",
            "Total params: 4,049,751\n",
            "Trainable params: 4,049,751\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZq_jjjfi8M2",
        "colab_type": "text"
      },
      "source": [
        "#Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2E4HeOvK7Fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 280\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    # remove the batch dimension\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "    # using a categorical distribution to predict the character returned by the model\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    # We pass the predicted character as the next input to the model\n",
        "    # along with the previous hidden state\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8HwlRlGfO-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "6d218449-f881-4c3f-921e-6aad878312e8"
      },
      "source": [
        "print(generate_text(model, start_string='The Foundation'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Foundation series had been written at a bitor of \n",
            "religious projectation medital rights to bring inch of sacrilege of the highest order?” \n",
            "\n",
            "Wienis presented his lips might and said: “Well, now, I have come to a complacency. \n",
            "\n",
            "“Back to the Imperie mean that had \n",
            "shoulders. In no \n",
            "\n",
            "\n",
            "\n",
            "passeng\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa-KUHdJNJoy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dfe48e44-861f-48da-9742-dfdb3d641f61"
      },
      "source": [
        "messages = ( 'Hi','How are you?',\"What's your name?\", 'Tell me about yourself',\n",
        "            'Do you love me?', \"What's the meaning of life?\", \"How is the weather today?\",\n",
        "            \"Let's have a dinner\", \"Are you a bot?\", \"Why not?\")\n",
        "\n",
        "for m in messages:\n",
        "  print('Input: '+m+'\\n')\n",
        "  print('output: '+generate_text(model, start_string=m).replace('/n', '\\n'))\n",
        "  print('\\n\\n')\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: Hi\n",
            "\n",
            "output: His possible. How would you believe e important things of \n",
            "metallically: “I seem to Twer shortly and began a ship its railings with believe in’s interested in par \n",
            "\n",
            "“What is it?” replay in One hands with events \n",
            "of economics and so forth. Its accepted cigars and breat diw \n",
            "bourdedi\n",
            "\n",
            "\n",
            "\n",
            "Input: How are you?\n",
            "\n",
            "output: How are you? Atho-d most power plants on their active is a vouches of the old Imperial Nyak of \n",
            "by unstracted reverie. “No, milord, \n",
            "cause Empire action to better his \n",
            "view. He resistance had removed the “Action to Lupon ‘have half ones of the Foundation. The known prod Dorngray; his kings o\n",
            "\n",
            "\n",
            "\n",
            "Input: What's your name?\n",
            "\n",
            "output: What's your name? We know that some \n",
            "day we’re to write a small man; Mr. A side is necessary. You mean what \n",
            "you do that I know -- not expansion of his vigile seco-sure that \n",
            "will final and wondered, -vanious men of the Galaxy, if you \n",
            "lack the ancient days when the Galaxy for heavious capable on\n",
            "\n",
            "\n",
            "\n",
            "Input: Tell me about yourself\n",
            "\n",
            "output: Tell me about yourself, Wienis. and the e dander If you are not \n",
            "solved by individuals but by historical might educated into all the motions of the published, and the little. “The Grand Master \n",
            "does Gorm accepted \n",
            "in the Seldon crisis to obvious to assume that he used his scantments n here. \n",
            "I’ve give\n",
            "\n",
            "\n",
            "\n",
            "Input: Do you love me?\n",
            "\n",
            "output: Do you love me? Repult Terminus as we could crisis coming up.” \n",
            "\n",
            "Mallow waited for it has launched another palace got nuclear blasts capable of \n",
            "boubse I’m Terminus of the \n",
            "Emperor’s--” \n",
            "\n",
            "“They’re not the on officers of the Periphery, and it was \n",
            "conscrupulation of the Foundation. He was Foreig\n",
            "\n",
            "\n",
            "\n",
            "Input: What's the meaning of life?\n",
            "\n",
            "output: What's the meaning of life?” \n",
            "\n",
            "The gleaming calmed and greater such as he. He will cheerfully cut yoursteem and \n",
            "called it “Foundation novel out to his underground Now, and shortly \n",
            "worry about them. Together we will remember the part of the Galactic \n",
            "Empire belonged in the old mastahs — the gweat accepted\n",
            "\n",
            "\n",
            "\n",
            "Input: How is the weather today?\n",
            "\n",
            "output: How is the weather today?” \n",
            "\n",
            "\n",
            "“But this what was but once more \n",
            "appeared in his hand. He opened it and said: \n",
            "\n",
            "“But whatever dry such \n",
            "conquest what I will died — the Foundation was med opposition councilmen, jobseekers, \n",
            "reformers, and crillar by oy blaster dropped population, \n",
            "grat fell ortained a Dorn\n",
            "\n",
            "\n",
            "\n",
            "Input: Let's have a dinner\n",
            "\n",
            "output: Let's have a dinner you yesterday.” \n",
            "\n",
            "“I will need that instrument.” \n",
            "\n",
            "“We worse, you may consider yourself a \n",
            "requirement of Anacreon’s kings. \n",
            "\n",
            "That didn’t mean I was writing not a shipping what if I’ve \n",
            "gone thwo-ars of the old Prefect of Anacreon, all-popped \n",
            "City Half Parth will considered and\n",
            "\n",
            "\n",
            "\n",
            "Input: Are you a bot?\n",
            "\n",
            "output: Are you a bot?” \n",
            "\n",
            "“Well, I know. A action is \n",
            "forced on you could apply reached domination of the \n",
            "last richest crowd. \n",
            "Doubleday answered himself from the last uniformed peer and \n",
            "rested his hand and fall of the Galactic Empire . 5 \n",
            "\n",
            "“And they will be right, though scarcely any will recognize\n",
            "\n",
            "\n",
            "\n",
            "Input: Why not?\n",
            "\n",
            "output: Why not? Why not goods and then some reason, but said Salvor \n",
            "the chair out of night and the series behind him, and added I tucaller, he went on, “you kindly helped us \n",
            "to as Ank. We were forced no one hand \n",
            "s, his eyes were maddened \n",
            "\n",
            "\n",
            "\n",
            "hollowed that. “What does it matter, then, if \n",
            "you\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or50crNQiu2I",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}